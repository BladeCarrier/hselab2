{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "tweets = pandas.DataFrame.from_csv(\"Tweets data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sentiment                                      SentimentText\n",
      "ItemID                                                              \n",
      "1               0                       is so sad for my APL frie...\n",
      "2               0                     I missed the New Moon trail...\n",
      "3               1                            omg its already 7:30 :O\n",
      "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
      "5               0           i think mi bf is cheating on me!!!   ...\n",
      "6               0                  or i just worry too much?        \n",
      "7               1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
      "8               0         Sunny Again        Work Tomorrow  :-|  ...\n",
      "9               1        handed in my uniform today . i miss you ...\n",
      "10              1           hmmmm.... i wonder how she my number @-)\n"
     ]
    }
   ],
   "source": [
    "print(tweets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = tweets[\"SentimentText\"]\n",
    "Y = tweets[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    text = <приведите текст к нижнему регистру>\n",
    "    \n",
    "    #<для начала будем использовать частоты букв как признаки>\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"    \n",
    "    for l in letters:\n",
    "        features.append(text.count(l))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#порежем данные\n",
    "X_train = X[:70000]\n",
    "Y_train = Y[:70000]\n",
    "X_test = X[70000:]\n",
    "Y_test = Y[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите логистическую регрессию>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opinion mining\n",
    "\n",
    "Давайте использовуем нашу модель чтобы понять, что людям сейчас нравится/не нравится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"testdata.txt\") as fin:\n",
    "    test_tweets = fin.read()[:-1].split('\\n')\n",
    "test_tweets = numpy.array(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\" I don\\'t care what anyone says, I like Hillary Clinton.'\n",
      " 'have an awesome time at purdue!..'\n",
      " \"Yep, I'm still in London, which is pretty awesome: P Remind me to post the million and one pictures that I took when I get back to Markham!...\"\n",
      " \"Have to say, I hate Paris Hilton's behavior but I do think she's kinda cute..\"\n",
      " 'i will love the lakers.']\n"
     ]
    }
   ],
   "source": [
    "print test_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ops = []\n",
    "for tweet in test_tweets:\n",
    "    X_ops.append(extract_features(tweet))\n",
    "X_ops = numpy.array(X_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments = <предскажите эмоциональную окраску x_ops>\n",
    "sentiment_order = numpy.argsort(-sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### теперь посмотрим на наиболее любимые/ненавистные людям вещи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999208674741 : OHMANJMANJMANJMANJMANJMNAJNDYUFSGDFG I love those Volkswagen commercials....\n",
      "0.994010901338 : As part of the AAdvantage ® Program's 25th Anniversary celebration, American Airlines is announcing an exciting elite rewards offer to AAdvantage Executive Platinum ®, AAdvantage Platinum ® and AAdvantage Gold ® members..\n",
      "0.980939788184 : I love Angelina Jolie, Heath Ledger, Jake Gyllenhall, Arnold Vosloo, Faruza Balk, Jason Wiles, Molly Price, Julia Roberts, Chris Meloni, Mariska Hargitay, Brendan Fraiser, Mel Gibson, Julian McMahon, Dennis Leary, Phillip Seymour Hoffman, Sean Patrick Thomas and more...\n",
      "0.978268233389 : Voila les dernières heures de Miss 307 SW passées en ma compagnie, avant de retrouver le monde cruel du parc automobile de chez Toyota en quête d ’ un nouveau propriétaire...\n",
      "0.975168102461 : People like Herb Kelleher of Southwest Airlines, Fred Smith of Federal Express, Mary Kay Ash of Mary Kay, Benjamin Franklin, Abraham Lincoln, Mahatma Gandhi, and Dr. Martin Luther King, Jr. are good examples.\n",
      "0.96930797283 : i love trains: ) and i like the commercials for citi for credit card fraud and the voice overs are always hilarious..\n",
      "0.968949177342 : Folgende Weblogs beziehen sich auf den Eintrag Exciting Commerce Workshop mit Werkstattberichten:..\n",
      "0.963745940899 : Happy Birthday to You, Sally -- your mother just checked finchfam and heard your exciting news about the Dallas Mavericks...\n",
      "0.960040239846 : One of China's richest men and a senior Shanghai municipal official are under investigation for their parts in an alleged improper loan involving 3.2 billion yuan ( US $ 400 million ) in city funds...\n",
      "0.958904314138 : wow all i know is that cory looks jokey in that picture well anyways yah i loved hangin out ata cheddars we should all do that again well anyways holla at yah boy lata skeedah(\n"
     ]
    }
   ],
   "source": [
    "best_ids = sentiment_order[:10]\n",
    "\n",
    "for tweet, score in zip(test_tweets[best_ids], sentiments[best_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0433397532784 : I MISS URARO huhuhuhu pero mahal ata sa filipino store.\n",
      "0.0381545259697 : AAA wats good me nothin just chillen man i had to go through a nother boring ass weekend but i aint got no mo 2 say so hit me back.\n",
      "0.0378698545171 : Purdue really sucks, and I dont mean just suck suck, but I mean the real word'suck ', \" Mark really sucks at singing!\n",
      "0.0269677065227 : In what should be an incredibly badly played game by two sucky ass teams, Purdue will probably suck it up big time tonight and get crushed by the Hurryin'Losers.\n",
      "0.0265778230249 : There were seriously points in the night when -- realizing that I was powerless to stop the noise -- I wanted to beat the black Hyundai Santa Fe into submission with my Mag Light or at least key it.\n",
      "0.0240677640007 : Shanghai sucked and it equivocally sucked and it sucked sucked sucked and I'll tell anyone who asks me why in painful detail.\n",
      "0.0232405771436 : but NO. no one posted'cept cory saying somtine was up my butt how rude i just mit shut this site down so i don't have to deal with it...\n",
      "0.0178689894264 : Sorry, didn't mean to shout, but all the GF bread I find here in London is horrible and can onnly be ingested when toasted.\n",
      "0.012066859678 : i remember i hated shanghai last year i didnt want to move i wanted to die nd i cried everyday nd hated everyone hated SAS and i didnt want to go there or be in shanghai.\n",
      "0.00347548278862 : OMFG HONDA SUCKS @ @ @ @ @ @ @ @ @ @ @ @ @ FORD A < > L < > L < > THE WAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY.\n"
     ]
    }
   ],
   "source": [
    "worst_ids = sentiment_order[-10:]\n",
    "\n",
    "for tweet, score in zip(test_tweets[worst_ids], sentiments[worst_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_words = <список всех слов>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = list(set(words))\n",
    "word_to_id = {word:i for i,word in enumerate(list(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#выделите 100 слов, которые имеют наиболее разную вероятность войти в позитивный и негативный твит\n",
    "bag_of_words = <слова-признаки>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    words = filter(len,text.lower().split())\n",
    "    \n",
    "    <bag of words для слов>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfinder = collocations.BigramCollocationFinder.from_words(text_words)\n",
    "cfinder.apply_freq_filter(5)\n",
    "measure = collocations.BigramAssocMeasures.raw_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 'the'), ('for', 'the'), ('on', 'the'), ('to', 'be'), ('have', 'to'), ('I', 'have'), ('have', 'a'), ('going', 'to'), ('I', 'was'), ('of', 'the'), ('I', 'am'), ('to', 'the'), ('to', 'see'), ('it', 'was'), ('I', \"don't\"), ('to', 'get'), ('I', 'think'), ('I', 'love'), ('a', 'good'), ('you', 'are'), ('to', 'go'), ('want', 'to'), ('at', 'the'), ('but', 'I'), ('for', 'a'), ('I', 'just'), ('I', \"can't\"), ('and', 'I'), ('need', 'to'), ('you', 'have'), ('on', 'my'), ('will', 'be'), ('i', 'have'), ('is', 'a'), ('in', 'a'), ('are', 'you'), ('I', 'know'), ('I', 'can'), ('to', 'do'), ('go', 'to'), ('thanks', 'for'), ('if', 'you'), ('I', 'hope'), ('i', 'was'), ('in', 'my'), ('a', 'great'), ('i', 'love'), ('all', 'the'), ('I', 'miss'), ('Thanks', 'for'), ('of', 'my'), ('the', 'same'), ('but', 'i'), ('I', 'want'), ('I', 'will'), ('I', 'had'), ('to', 'hear'), ('had', 'a'), ('see', 'you'), ('with', 'the'), ('is', 'the'), ('it', 'is'), ('would', 'be'), ('for', 'me'), ('like', 'a'), ('so', 'much'), ('you', 'can'), ('and', 'i'), ('out', 'of'), ('was', 'a'), ('be', 'a'), ('one', 'of'), ('I', 'wish'), ('hope', 'you'), ('I', 'need'), ('when', 'I'), ('I', \"didn't\"), ('do', 'you'), ('to', 'have'), (\"I'm\", 'not'), ('a', 'lot'), ('I', 'got'), ('i', 'am'), ('miss', 'you'), ('i', 'think'), ('get', 'to'), ('love', 'you'), ('i', 'miss'), ('i', 'know'), ('thank', 'you'), ('I', 'would'), ('I', 'like'), ('I', 'could'), ('for', 'you'), ('a', 'few'), ('to', 'you'), ('I', 'feel'), ('back', 'to'), ('on', 'a'), ('wish', 'I')]\n"
     ]
    }
   ],
   "source": [
    "print(cfinder.nbest(measure,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    <bag of words для коллокаций>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
